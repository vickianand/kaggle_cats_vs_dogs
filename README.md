# Cats and Dogs classification - Kaggle competition for IFT6135H19 Assignment 1

## Data

Download data from the [Kaggle competition page](https://www.kaggle.com/c/ift6135h19/data).

## Training

Run `python train.py --train_folder <path to folder having images>`

```
usage: train.py [-h] [--train_folder TRAIN_FOLDER] [--model_path MODEL_PATH]
                [--batch_norm] [--decreasing_lr]

optional arguments:
  -h, --help            show this help message and exit
  --train_folder TRAIN_FOLDER
                        Path to the folder having training images
  --model_path MODEL_PATH
                        Path to the folder where models to be saved
  --batch_norm          add this flag if you want to add batch_norm layer
                        after every conv layer
  --decreasing_lr       add this flag if you want to decrease learning-rate by
                        multiplying with 0.99 after every epoch
```

## Prediction

Run

```bash
python predict.py --image_folder <path to folder having images> --model_path <path to model state_dict file>
```

Note : `<path to folder having images>` Should have images in subfolders and not directly inside the folder. Subfolders are considered are classes.
For prediction a single dummy subfolder can be created. In this case class is obviously ignored.

## Generating training curves

We have written the `plot_logs.py` script to parse the logs generated by `train.py` script and plot training curves (training and validation losses and accuracies against epoch).

```bash
usage: plot_logs.py [-h] [--log LOG] [--save] [--max_epoch MAX_EPOCH]

optional arguments:
  -h, --help            show this help message and exit
  --log LOG             Path to log file generated by train.py
  --save                add this flag if you want to save the generated plots
  --max_epoch MAX_EPOCH
                        Number of epochs to parse
```

Example: `python plot_logs.py --log ../logs/m2_vggtype_64_128_256_train.log --save --max_epoch 35` will generate the training & validation loss and accuracy curves. It will save them in same location as the log-file provided to it.

## Visualization scripts
There are two scripts.

* `get_validn_mispredictions.py` for finding mis-predicted and confusing images from validation set .
    - Run: `python get_validn_mispredictions.py --batch_norm`

* `visualize_convnet.py` for generating outputs from each layer of the M3 model.
    - Run: `python visualize_convnet.py`